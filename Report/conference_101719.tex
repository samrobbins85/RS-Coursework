\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{xcolor}
\usepackage{multirow}
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\begin{document}

\title{Recommender Systems}

\author{\IEEEauthorblockN{mbkb74}
    \IEEEauthorblockA{\textit{Department of Computer Science} \\
        \textit{Durham University}\\
        Durham, United Kingdom \\}

}

\maketitle

\begin{abstract}
    This document is a model and instructions for \LaTeX.
    This and the IEEEtran.cls file define the components of your paper [title, text, heads, etc.]. *CRITICAL: Do Not Use Symbols, Special Characters, Footnotes,
    or Math in Paper Title or Abstract.
\end{abstract}

\begin{IEEEkeywords}
    component, formatting, style, styling, insert
\end{IEEEkeywords}

\section{Introduction}

\subsection{Domain of application}

This application works on Italian restaurants.

\subsection{Related work review}

\subsection{Purpose/aim}

The aim of this application is to recommend an Italian restaurant to the user.


\section{Methods}

\subsection{Data description}

The data is from the Yelp dataset \cite{b1}, this contains a list of the businesses on Yelp, detailing which categories they fall under. It also contains all the reviews, including a written review along with a range of scores. This also now contains a COVID-19 dataset, which lists the changes businesses are making due to COVID-19. There are around 8 million reviews in the review dataset.

\subsection{Data preparation and feature selection}

In order to make the data easier to process, along with increasing the accuracy of predictions, it is needed to reduce the number of reviews. First I selected just restaurants, but as this is a large part of Yelp, it only reduced the dataset to 5 million reviews. So I have reduced it to just Italian restaurants, shrinking the dataset to around 470k reviews. In addition, limiting the timescale reduces the impact of tastes changing over time, so I have only included reviews after 2016. This reduced the number of reviews to around 270k, which is enough to give a good sample, but small enough to be practical to process.

\subsection{Hybrid scheme}

This uses a weighted hybrid scheme, with each recommender contributing half towards the final result. The scores for each are summed and halved to generate a final score for each restaurant.

\subsection{Recommendation techniques/algorithms}

There are two recommenders used here, content-based filtering and collaborative filtering. The content-based filtering works on the text of the reviews to find reviews that use similar words. An example of this is that if someone describes a restaurant as "cosy", then it will find other reviews that use the same word. Collaborative filtering looks at the restaurants the user has reviewed and finds people who have reviewed those restaurants in the same way and looks at their reviews of other restaurants to find the best restaurants.

Furthermore the COVID-19 dataset is used to check the list of suggested restaurants and remove those that are closed as the user wouldn't be able to visit them.

\subsection{Evaluation methods}

\section{Implementation}

\subsection{Input interface}

For the input for this application, the user can choose which user they are from a list of 10 randomly selected users from a list of users that have made lots of reviews. This is done so that the recommenders have more data to work with, providing more accurate results.

\subsection{Recommendation algorithm}

I find the count of the reviews for each business, and for each user I find how many reviews they have left. Then I only select the 300 most reviewed businesses, this allows for better predictions to be made. I then choose the 100 users who have left the most reviews and take a random sample of 10 to present to the user of the program. Likewise this allows for better predictions. Obviously in a real application you would choose your user from the whole set of users, but this provides more interesting data.

This is where I use content based filtering. From \texttt{sklearn} I use the \texttt{TfidfVectorisor} to get the TF-IDF matrix, then use the \texttt{linear\_kernel} function between this matrix and the same matrix, but only including the user reviews. I then use these scores and choose the 300 best matches and merge this with the 300 most reviewed businesses previously found, to generate a smaller list where the restaurant is in both sets.

For each users rating of a restaurant, I group repeated ratings of the same restaurant as the average, this allows for better representation as one person rating the same restaurant 5 stars lots of time shouldn't have more impact than once. I then generate the cosine similarity between all the restaurants as a matrix, using the ratings. For each restaurant the recommender wants to get a prediction for, the recommender loops over the cosine similarities generated for that item. This is to generate an adjusted weighted average, using the formula

$$
    AdjAvg=ItemAvg+\dfrac{\sum (cosSim \times (userScore-itemAvg))}{\sum cosSim}
$$

This concludes the collaborative filtering section. I then choose the 5 largest scores to present to the user, and remove any which are shown in the COVID dataset as not open.

\subsection{Output interface}

The output for this system is a list of 5 restaurants the user would most like, along with their COVID-19 notice so the user knows how to prepare.

\section{Evaluation results}

\subsection{Comparison against baseline implementation}

The hybrid implementation yields the following confusion matrix

\begin{tabular}{l|l|c|c|}
    \multicolumn{2}{c}{}&\multicolumn{2}{c}{Recommender}\\
    \cline{3-4}
    \multicolumn{2}{c|}{}&High&Low\\
    \cline{2-4}
    \multirow{2}{*}{User Rating}& High & 14& 19\\
    \cline{2-4}
    & Low & 5 & 7\\
    \cline{2-4}

\end{tabular}
\\
\\
This gives the following statistics:
\begin{itemize}
    \item Precision 74\%
    \item Recall 42 \%
    \item Specificity 58\%
\end{itemize}
\vspace{2mm}
Whereas the baseline implementation of just collaborative filtering gives the confusion matrix

\begin{tabular}{l|l|c|c|}
    \multicolumn{2}{c}{}&\multicolumn{2}{c}{Recommender}\\
    \cline{3-4}
    \multicolumn{2}{c|}{}&High&Low\\
    \cline{2-4}
    \multirow{2}{*}{User Rating}& High & 21 & 4\\
    \cline{2-4}
    & Low & 8 & 5\\
    \cline{2-4}

\end{tabular}
\\
\\
Giving these statistics:
\begin{itemize}
    \item Precision 72 \%
    \item Recall 84 \%
    \item Specificity 38 \%
\end{itemize}

Finally the baseline implementation of content-based filtering gives the confusion matrix
\begin{tabular}{l|l|c|c|}
    \multicolumn{2}{c}{}&\multicolumn{2}{c}{Recommender}\\
    \cline{3-4}
    \multicolumn{2}{c|}{}&High&Low\\
    \cline{2-4}
    \multirow{2}{*}{User Rating}& High & 10 & 23\\
    \cline{2-4}
    & Low & 3 & 8\\
    \cline{2-4}

\end{tabular}
\\
\\
Giving these statistics:
\begin{itemize}
    \item Precision 77 \%
    \item Recall 30 \%
    \item Specificity 72 \%
\end{itemize}

Collaborative filtering has poor specificity, not predicting negative values well, whereas content-based filtering has poor recall, not predicting positive values well. This is a good case for a hybrid recommender as my merging them it helps to smooth the incorrect results.

\subsection{Comparison against hybrid recommenders in related studies}

\subsection{Ethical Issues}

\section{Conclusion}

\subsection{Limitations}

\subsection{Further developments}


\begin{thebibliography}{00}
    \bibitem{b1} Yelp Dataset. https://www.yelp.com/dataset
\end{thebibliography}


\end{document}
